{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbCImMyh-j_j"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_excel('/content/EastWestAirlines.xlsx')\n",
        "\n",
        "# Display the first few rows and the data types\n",
        "print(df.head())  # Preview data\n",
        "print(df.dtypes)  # Check the types of columns\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all columns to numeric where possible (non-convertible values will be set to NaN)\n",
        "df_converted = df.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Check the data types after conversion\n",
        "print(df_converted.dtypes)\n",
        "\n",
        "# Preview the converted data\n",
        "print(df_converted.head())\n"
      ],
      "metadata": {
        "id": "t1If5_maBRt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop columns that are completely non-numeric or contain only NaN values\n",
        "df_clean = df_converted.dropna(axis=1, how='all')\n",
        "\n",
        "# Drop rows with any missing values\n",
        "df_clean = df_clean.dropna()\n",
        "\n",
        "# Check the cleaned data\n",
        "print(df_clean.head())\n"
      ],
      "metadata": {
        "id": "VE-t01AuBV5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Ensure there is data left after cleaning\n",
        "if not df_clean.empty:\n",
        "    # Perform feature scaling\n",
        "    scaler = StandardScaler()\n",
        "    scaled_data = scaler.fit_transform(df_clean)\n",
        "\n",
        "    # Check the shape of the scaled data\n",
        "    print(f\"Scaled Data Shape: {scaled_data.shape}\")\n",
        "else:\n",
        "    print(\"No numeric data available for scaling.\")\n"
      ],
      "metadata": {
        "id": "eY7LvPTCBb_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape of the cleaned dataset\n",
        "print(f\"Number of samples: {df_clean.shape[0]}\")\n"
      ],
      "metadata": {
        "id": "f9yvJAN_BeL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Use the Elbow method to find the optimal number of clusters (adjust K range to fit sample size)\n",
        "max_clusters = min(10, df_clean.shape[0])  # Limit K to the number of samples or 10\n",
        "inertia = []\n",
        "K = range(1, max_clusters + 1)\n",
        "for k in K:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(scaled_data)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "# Plot the Elbow curve\n",
        "plt.plot(K, inertia, 'bo-')\n",
        "plt.title('Elbow Method For Optimal K')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('Inertia')\n",
        "plt.show()\n",
        "\n",
        "# Apply K-Means with the optimal number of clusters (based on the elbow curve)\n",
        "optimal_k = 2  # Adjust based on the elbow curve or manually set a reasonable value\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
        "kmeans_labels = kmeans.fit_predict(scaled_data)\n",
        "\n",
        "# Silhouette Score for K-Means\n",
        "silhouette_kmeans = silhouette_score(scaled_data, kmeans_labels)\n",
        "print(f'Silhouette Score for K-Means: {silhouette_kmeans:.2f}')\n"
      ],
      "metadata": {
        "id": "pMgRLgAuBggt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "# Perform hierarchical clustering (linkage method can be 'ward', 'complete', 'average', etc.)\n",
        "linked = linkage(scaled_data, method='ward')\n",
        "\n",
        "# Plot the dendrogram\n",
        "plt.figure(figsize=(10, 7))\n",
        "dendrogram(linked)\n",
        "plt.title('Dendrogram')\n",
        "plt.xlabel('Samples')\n",
        "plt.ylabel('Euclidean distances')\n",
        "plt.show()\n",
        "\n",
        "# Apply Agglomerative Clustering\n",
        "# Replace 'affinity' with 'metric' for newer versions of scikit-learn\n",
        "hierarchical = AgglomerativeClustering(n_clusters=3, metric='euclidean', linkage='ward')\n",
        "hierarchical_labels = hierarchical.fit_predict(scaled_data)\n",
        "\n",
        "# Silhouette Score for Hierarchical Clustering\n",
        "silhouette_hierarchical = silhouette_score(scaled_data, hierarchical_labels)\n",
        "print(f'Silhouette Score for Hierarchical Clustering: {silhouette_hierarchical:.2f}')\n"
      ],
      "metadata": {
        "id": "cslF1V_4CG0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Apply DBSCAN (experiment with different epsilon and min_samples)\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=2)  # Adjust eps and min_samples as needed\n",
        "dbscan_labels = dbscan.fit_predict(scaled_data)\n",
        "\n",
        "# Silhouette Score for DBSCAN (only if it creates clusters)\n",
        "if len(set(dbscan_labels)) > 1:  # Check if there are more than one cluster\n",
        "    silhouette_dbscan = silhouette_score(scaled_data, dbscan_labels)\n",
        "    print(f'Silhouette Score for DBSCAN: {silhouette_dbscan:.2f}')\n",
        "else:\n",
        "    print(\"DBSCAN did not form clusters or only formed one cluster.\")\n"
      ],
      "metadata": {
        "id": "-_kmJEX3CMXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape of the scaled data\n",
        "print(f\"Scaled Data Shape: {scaled_data.shape}\")\n"
      ],
      "metadata": {
        "id": "IiH2cBN1CuEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single feature visualization for K-Means\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x=range(len(scaled_data)), y=scaled_data[:, 0], hue=kmeans_labels, palette='Set1')\n",
        "plt.title('K-Means Clustering (Single Feature)')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Feature Value')\n",
        "plt.legend(title='K-Means Clusters')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hriO_pW7DNrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single feature visualization for Hierarchical Clustering\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x=range(len(scaled_data)), y=scaled_data[:, 0], hue=hierarchical_labels, palette='Set2')\n",
        "plt.title('Hierarchical Clustering (Single Feature)')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Feature Value')\n",
        "plt.legend(title='Hierarchical Clusters')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pOxPW4tKDe7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single feature visualization for DBSCAN Clustering\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x=range(len(scaled_data)), y=scaled_data[:, 0], hue=dbscan_labels, palette='Set3')\n",
        "plt.title('DBSCAN Clustering (Single Feature)')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Feature Value')\n",
        "plt.legend(title='DBSCAN Clusters')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Qo3BevyPDi1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HMgFyHAcDlhJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}