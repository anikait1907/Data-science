{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSRkW9m3eSLL"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. Load the dataset\n",
        "# Make sure you load the dataset 'ToyotaCorolla - MLR.csv' correctly\n",
        "df = pd.read_csv('/content/ToyotaCorolla - MLR.csv')\n",
        "\n",
        "# Show basic dataset info and summary statistics\n",
        "print(df.head())      # Display the first few rows of the data\n",
        "print(df.info())      # Info on data types and missing values\n",
        "print(df.describe())  # Summary statistics for numerical features\n",
        "\n",
        "# 2. Exploratory Data Analysis (EDA)\n",
        "\n",
        "# Histograms for all numerical variables to understand their distribution\n",
        "df.hist(bins=20, figsize=(10, 10))\n",
        "plt.show()\n",
        "\n",
        "# Pairplot to visualize relationships between numerical variables\n",
        "sns.pairplot(df)\n",
        "plt.show()\n",
        "\n",
        "# Correlation matrix heatmap to identify linear relationships\n",
        "# First, convert categorical variables into dummy/indicator variables\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Compute correlation matrix only for numeric columns\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "# Display the heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
        "plt.show()\n",
        "\n",
        "# 3. Preprocess the dataset\n",
        "# Split the dataset into features (X) and target (y)\n",
        "X = df.drop('Price', axis=1)  # All columns except 'Price' are features\n",
        "y = df['Price']               # 'Price' is the target variable\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. Build a Multiple Linear Regression Model\n",
        "\n",
        "# Initialize the linear regression model\n",
        "lr = LinearRegression()\n",
        "\n",
        "# Fit the model to the training data\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "# Evaluate the model performance\n",
        "mse = mean_squared_error(y_test, y_pred)  # Mean Squared Error\n",
        "r2 = r2_score(y_test, y_pred)             # R² score\n",
        "\n",
        "# Print the results\n",
        "print(f\"Linear Regression Mean Squared Error: {mse}\")\n",
        "print(f\"Linear Regression R² Score: {r2}\")\n",
        "\n",
        "# Print the coefficients of the linear model\n",
        "coefficients = pd.DataFrame({'Feature': X_train.columns, 'Coefficient': lr.coef_})\n",
        "print(coefficients)\n",
        "\n",
        "# 5. Apply Regularization Techniques: Lasso and Ridge\n",
        "\n",
        "# Lasso Regression (L1 Regularization)\n",
        "lasso = Lasso(alpha=0.1)  # Adjust alpha (regularization strength) as needed\n",
        "lasso.fit(X_train, y_train)\n",
        "y_pred_lasso = lasso.predict(X_test)\n",
        "\n",
        "# Evaluate Lasso Regression\n",
        "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
        "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
        "print(f\"Lasso Regression Mean Squared Error: {mse_lasso}\")\n",
        "print(f\"Lasso Regression R² Score: {r2_lasso}\")\n",
        "\n",
        "# Ridge Regression (L2 Regularization)\n",
        "ridge = Ridge(alpha=0.1)  # Adjust alpha (regularization strength) as needed\n",
        "ridge.fit(X_train, y_train)\n",
        "y_pred_ridge = ridge.predict(X_test)\n",
        "\n",
        "# Evaluate Ridge Regression\n",
        "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
        "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
        "print(f\"Ridge Regression Mean Squared Error: {mse_ridge}\")\n",
        "print(f\"Ridge Regression R² Score: {r2_ridge}\")\n",
        "\n",
        "# 6. Optional: Standardization (for models like Lasso and Ridge to perform better)\n",
        "\n",
        "# Initialize a standard scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Standardize the training and test datasets\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Apply Lasso on standardized data\n",
        "lasso_scaled = Lasso(alpha=0.1)\n",
        "lasso_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_lasso_scaled = lasso_scaled.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate Lasso on standardized data\n",
        "mse_lasso_scaled = mean_squared_error(y_test, y_pred_lasso_scaled)\n",
        "r2_lasso_scaled = r2_score(y_test, y_pred_lasso_scaled)\n",
        "print(f\"Standardized Lasso Regression Mean Squared Error: {mse_lasso_scaled}\")\n",
        "print(f\"Standardized Lasso Regression R² Score: {r2_lasso_scaled}\")\n",
        "\n",
        "# Apply Ridge on standardized data\n",
        "ridge_scaled = Ridge(alpha=0.1)\n",
        "ridge_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_ridge_scaled = ridge_scaled.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate Ridge on standardized data\n",
        "mse_ridge_scaled = mean_squared_error(y_test, y_pred_ridge_scaled)\n",
        "r2_ridge_scaled = r2_score(y_test, y_pred_ridge_scaled)\n",
        "print(f\"Standardized Ridge Regression Mean Squared Error: {mse_ridge_scaled}\")\n",
        "print(f\"Standardized Ridge Regression R² Score: {r2_ridge_scaled}\")\n",
        "\n",
        "# Interview Questions\n",
        "# 1. What is Normalization & Standardization and how is it helpful?\n",
        "# Normalization and standardization are techniques used to scale numeric data to a common range, usually between 0 and 1, to prevent features with large ranges from dominating the model.\n",
        "# This is helpful because many machine learning algorithms are sensitive to the scale of the data, and scaling the data can improve the performance of the model.\n",
        "\n",
        "# 2. What techniques can be used to address multicollinearity in multiple linear regression?\n",
        "# Techniques to address multicollinearity include:\n",
        "# 1. Dropping one of the correlated variables\n",
        "# 2. Using dimensionality reduction techniques, such as PCA\n",
        "# 3. Using regularization techniques, such as Lasso or Ridge regression\n",
        "# 4. Using a different model, such as a generalized linear model or a decision tree model\n",
        "\n",
        "# Assumptions made during the analysis:\n",
        "# 1. Linearity: The relationship between the features and the target variable is assumed to be linear.\n"
      ]
    }
  ]
}